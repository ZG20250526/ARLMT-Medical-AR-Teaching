(llava) guoyunfei@tme-GS4840:~/projects/LLaVA-main/llava$ TRANSFORMERS_OFFLINE=1 HF_HUB_OFFLINE=1 . finetune.sh 
[2024-07-30 13:51:09,152] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:11,267] [WARNING] [runner.py:202:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
[2024-07-30 13:51:11,267] [INFO] [runner.py:571:main] cmd = /home/guoyunfei/.conda/envs/llava/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None /home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py --deepspeed /home/guoyunfei/projects/LLaVA-main/scripts/zero2.json --model_name_or_path /data0/GYF/offline_model/liuhaotian/llava-v1.6-mistral-7b --version plain --data_path /data0/GYF/data/llava-med/data/Instruction-Tuning/llava_med_instruct_10k-2024072902.json --image_folder /data0/GYF/data/llava-med/data/images --vision_tower /data0/GYF/offline_model/openai/clip-vit-large-patch14 --pretrain_mm_mlp_adapter ./checkpoints/llava-v1.6-7b-13GB-pretrain/mm_projector.bin --mm_vision_select_layer -2 --mm_use_im_start_end False --mm_use_im_patch_token False --bf16 True --output_dir ./checkpoints/llava-v1.6-7b_plain-finetune --num_train_epochs 1 --per_device_train_batch_size 16 --per_device_eval_batch_size 4 --gradient_accumulation_steps 1 --evaluation_strategy no --save_strategy steps --save_steps 50000 --save_total_limit 1 --learning_rate 2e-5 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 1 --tf32 True --model_max_length 2048 --gradient_checkpointing True --dataloader_num_workers 4 --lazy_preprocess True --report_to wandb
[2024-07-30 13:51:13,703] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:15,727] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}
[2024-07-30 13:51:15,727] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0
[2024-07-30 13:51:15,727] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})
[2024-07-30 13:51:15,727] [INFO] [launch.py:163:main] dist_world_size=8
[2024-07-30 13:51:15,727] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
[2024-07-30 13:51:19,415] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:19,614] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:19,644] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:19,756] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:19,861] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:19,872] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:19,933] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:19,956] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-07-30 13:51:21,045] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-30 13:51:21,048] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-30 13:51:21,093] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-30 13:51:21,193] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-30 13:51:21,303] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-30 13:51:21,348] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-30 13:51:21,348] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-07-30 13:51:21,392] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-07-30 13:51:21,476] [INFO] [comm.py:637:init_distributed] cdb=None
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
You are using a model of type llava_mistral to instantiate a model of type llava_llama. This is not supported for all configurations of models and can yield errors.
You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.
Loading checkpoint shards:   0%|                                                                                        | 0/4 [00:00<?, ?it/s]/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  25%|████████████████████                                                            | 1/4 [00:05<00:15,  5.17s/it]/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  25%|████████████████████                                                            | 1/4 [00:03<00:10,  3.66s/it]/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:14<00:00,  3.60s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:19<00:00,  4.96s/it]
Loading checkpoint shards:  50%|████████████████████████████████████████                                        | 2/4 [00:07<00:07,  3.98s/it]openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.31s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.49s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.48s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.50s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.39s/it]
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████| 4/4 [00:17<00:00,  4.36s/it]
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
Formatting inputs...Skip in lazy mode
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
openai/clip-vit-large-patch14-336 is already loaded, `load_model` called again, skipping.
wandb: Currently logged in as: james20201124 (james20201124-temple-university). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.17.5
wandb: Run data is saved locally in /home/guoyunfei/projects/LLaVA-main/llava/wandb/run-20240730_135305-b1l823yo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-pyramid-13
wandb: ⭐️ View project at https://wandb.ai/james20201124-temple-university/huggingface
wandb: 🚀 View run at https://wandb.ai/james20201124-temple-university/huggingface/runs/b1l823yo
  0%|                                                                                                                  | 0/14 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/22166090_F1.jpg'

Traceback (most recent call last):
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
Traceback (most recent call last):
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/30128402_fig2.jpg'

    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
Traceback (most recent call last):
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    data.reraise()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/23418431_pone-0054841-g002.jpg'

    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
Traceback (most recent call last):
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    return self._process_data(data)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/32161778_j_med-2020-0015_fig_001.jpg'

    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/25422616_F1.jpg'

Traceback (most recent call last):
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/28856103_fig0005.jpg'

Traceback (most recent call last):
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
Traceback (most recent call last):
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py", line 4, in <module>
    train(attn_implementation="flash_attention_2")
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 971, in train
    trainer.train()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/transformers/trainer.py", line 1836, in _inner_training_loop
    for step, inputs in enumerate(epoch_iterator):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/accelerate/data_loader.py", line 384, in __iter__
    current_batch = next(dataloader_iter)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
    return self._process_data(data)  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()

  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/19918449_fig-001.jpg'

    data.reraise()
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/_utils.py", line 694, in reraise
    raise exception
FileNotFoundError: Caught FileNotFoundError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/guoyunfei/projects/LLaVA-main/llava/train/train.py", line 701, in __getitem__
    image = Image.open(os.path.join(image_folder, image_file)).convert('RGB')
  File "/home/guoyunfei/.conda/envs/llava/lib/python3.10/site-packages/PIL/Image.py", line 3431, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '/data0/GYF/data/llava-med/data/images/17118178_F1.jpg'

[2024-07-30 13:53:21,886] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523438
[2024-07-30 13:53:22,554] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523439
[2024-07-30 13:53:22,583] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523440
[2024-07-30 13:53:22,607] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523441
[2024-07-30 13:53:22,607] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523442
[2024-07-30 13:53:22,632] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523443
[2024-07-30 13:53:22,656] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523444
[2024-07-30 13:53:22,683] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 2523445
[2024-07-30 13:53:22,712] [ERROR] [launch.py:321:sigkill_handler] ['/home/guoyunfei/.conda/envs/llava/bin/python', '-u', '/home/guoyunfei/projects/LLaVA-main/llava/train/train_mem.py', '--local_rank=7', '--deepspeed', '/home/guoyunfei/projects/LLaVA-main/scripts/zero2.json', '--model_name_or_path', '/data0/GYF/offline_model/liuhaotian/llava-v1.6-mistral-7b', '--version', 'plain', '--data_path', '/data0/GYF/data/llava-med/data/Instruction-Tuning/llava_med_instruct_10k-2024072902.json', '--image_folder', '/data0/GYF/data/llava-med/data/images', '--vision_tower', '/data0/GYF/offline_model/openai/clip-vit-large-patch14', '--pretrain_mm_mlp_adapter', './checkpoints/llava-v1.6-7b-13GB-pretrain/mm_projector.bin', '--mm_vision_select_layer', '-2', '--mm_use_im_start_end', 'False', '--mm_use_im_patch_token', 'False', '--bf16', 'True', '--output_dir', './checkpoints/llava-v1.6-7b_plain-finetune', '--num_train_epochs', '1', '--per_device_train_batch_size', '16', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '1', '--evaluation_strategy', 'no', '--save_strategy', 'steps', '--save_steps', '50000', '--save_total_limit', '1', '--learning_rate', '2e-5', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '1', '--tf32', 'True', '--model_max_length', '2048', '--gradient_checkpointing', 'True', '--dataloader_num_workers', '4', '--lazy_preprocess', 'True', '--report_to', 'wandb'] exits with return code = 1

