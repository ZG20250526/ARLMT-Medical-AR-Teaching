#!/bin/bash

# GitHub Repository Setup Script for ARLMT Project
# This script automates the setup of a GitHub repository according to PLOS journal requirements

set -e  # Exit on any error

# Configuration
REPO_NAME="ARLMT-Medical-AR-Teaching-System"
REPO_DESCRIPTION="Augmented Reality Large Language Model Medical Teaching System with QLoRA Fine-tuning"
GITHUB_USERNAME="ZG20250526"
PROJECT_URL="https://github.com/users/ZG20250526/projects/1/views/1"
BRANCH_NAME="main"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Logging function
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[WARNING] $1${NC}"
}

error() {
    echo -e "${RED}[ERROR] $1${NC}"
    exit 1
}

info() {
    echo -e "${BLUE}[INFO] $1${NC}"
}

# Check prerequisites
check_prerequisites() {
    log "Checking prerequisites..."
    
    # Check if git is installed
    if ! command -v git &> /dev/null; then
        error "Git is not installed. Please install git first."
    fi
    
    # Check if gh CLI is installed
    if ! command -v gh &> /dev/null; then
        warn "GitHub CLI (gh) is not installed. Some features may not work."
        warn "Install with: sudo apt install gh (Ubuntu/Debian) or brew install gh (macOS)"
    fi
    
    # Check if we're in the correct directory
    if [[ ! -f "ARLMT20250608.tex" ]]; then
        error "This script should be run from the LLaVA-main directory containing ARLMT20250608.tex"
    fi
    
    log "Prerequisites check completed."
}

# Initialize git repository
init_git_repo() {
    log "Initializing Git repository..."
    
    # Initialize git if not already initialized
    if [[ ! -d ".git" ]]; then
        git init
        log "Git repository initialized."
    else
        info "Git repository already exists."
    fi
    
    # Set default branch to main
    git config init.defaultBranch main
    git checkout -b main 2>/dev/null || git checkout main
    
    log "Git repository setup completed."
}

# Create .gitignore file
create_gitignore() {
    log "Creating .gitignore file..."
    
    cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
PYTHON

# PyTorch
*.pth
*.pt
checkpoints/
logs/
runs/
tensorboard_logs/

# Jupyter Notebook
.ipynb_checkpoints

# Environment variables
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Large files (use Git LFS instead)
*.zip
*.tar.gz
*.rar
*.7z

# Model files (use Git LFS)
*.bin
*.safetensors
models/
weights/

# Data files
data/raw/
data/processed/
*.csv
*.json
*.jsonl

# Logs
*.log
logs/

# Temporary files
tmp/
temp/
*.tmp

# Medical data (ensure no PHI)
patient_data/
medical_records/
phi/

# AR specific
*.unity
*.unitypackage
Library/
Temp/
Obj/
Build/
Builds/
Assets/AssetStoreTools*

# Documentation build
_build/
_static/
_templates/

# Coverage reports
htmlcov/
.coverage
.coverage.*
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Secrets and keys
*.key
*.pem
*.crt
*.p12
secrets/
keys/
credentials/

# Cache
.cache/
.mypy_cache/
.dmypy.json
dmypy.json

# Profiling
.prof

# Database
*.db
*.sqlite
*.sqlite3

# Node.js (if any frontend components)
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Package files
*.deb
*.rpm
*.msi
*.dmg

# Backup files
*.bak
*.backup
*.old

# Research specific
experiments/
results/
output/
figures/
plots/

# LaTeX
*.aux
*.bbl
*.blg
*.fdb_latexmk
*.fls
*.log
*.out
*.synctex.gz
*.toc
*.lof
*.lot
*.idx
*.ind
*.ilg
*.nav
*.snm
*.vrb
*.bcf
*.run.xml

# Specific to this project
ARLMT20250608.pdf
*.dated_backup
old_versions/
EOF

    log ".gitignore file created."
}

# Create Git LFS configuration
setup_git_lfs() {
    log "Setting up Git LFS for large files..."
    
    # Check if git-lfs is installed
    if ! command -v git-lfs &> /dev/null; then
        warn "Git LFS is not installed. Large files will not be tracked properly."
        warn "Install with: sudo apt install git-lfs (Ubuntu/Debian) or brew install git-lfs (macOS)"
        return
    fi
    
    # Initialize Git LFS
    git lfs install
    
    # Track large file types
    git lfs track "*.pth"
    git lfs track "*.pt"
    git lfs track "*.bin"
    git lfs track "*.safetensors"
    git lfs track "*.h5"
    git lfs track "*.hdf5"
    git lfs track "*.pkl"
    git lfs track "*.pickle"
    git lfs track "*.npz"
    git lfs track "*.zip"
    git lfs track "*.tar.gz"
    git lfs track "*.rar"
    git lfs track "*.7z"
    git lfs track "*.mp4"
    git lfs track "*.avi"
    git lfs track "*.mov"
    git lfs track "*.pdf"
    git lfs track "models/**"
    git lfs track "weights/**"
    git lfs track "checkpoints/**"
    
    log "Git LFS configuration completed."
}

# Create GitHub repository structure
organize_repository() {
    log "Organizing repository structure..."
    
    # Create main directories
    mkdir -p {\
        src/{arlmt_core,qlora_implementation,ar_interface,evaluation,utils},\
        models/{pretrained,fine_tuned,quantized},\
        data/{synthetic,benchmarks,examples},\
        docs/{api,user_guide,technical_specs,tutorials},\
        scripts/{training,evaluation,deployment,data_processing},\
        tests/{unit,integration,performance},\
        configs/{model,training,deployment},\
        examples/{basic,advanced,medical_scenarios},\
        tools/{preprocessing,visualization,analysis},\
        docker,\
        .github/{workflows,ISSUE_TEMPLATE,PULL_REQUEST_TEMPLATE}\
    }
    
    log "Repository structure created."
}

# Create GitHub workflow files
create_github_workflows() {
    log "Creating GitHub Actions workflows..."
    
    # CI/CD workflow
    cat > .github/workflows/ci.yml << 'EOF'
name: Continuous Integration

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, '3.10']
    
    steps:
    - uses: actions/checkout@v4
      with:
        lfs: true
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black isort
    
    - name: Lint with flake8
      run: |
        flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Check code formatting with black
      run: black --check src/ tests/
    
    - name: Check import sorting with isort
      run: isort --check-only src/ tests/
    
    - name: Test with pytest
      run: |
        pytest tests/ --cov=src/ --cov-report=xml --cov-report=html
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
EOF

    # Documentation workflow
    cat > .github/workflows/docs.yml << 'EOF'
name: Documentation

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-docs:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install sphinx sphinx-rtd-theme myst-parser
        pip install -r requirements.txt
    
    - name: Build documentation
      run: |
        cd docs/
        make html
    
    - name: Deploy to GitHub Pages
      if: github.ref == 'refs/heads/main'
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./docs/_build/html
EOF

    # Model validation workflow
    cat > .github/workflows/model-validation.yml << 'EOF'
name: Model Validation

on:
  push:
    paths:
      - 'models/**'
      - 'src/arlmt_core/**'
      - 'src/qlora_implementation/**'
  pull_request:
    paths:
      - 'models/**'
      - 'src/arlmt_core/**'
      - 'src/qlora_implementation/**'

jobs:
  validate-models:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
      with:
        lfs: true
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install torch torchvision transformers
        pip install -r requirements.txt
    
    - name: Validate model files
      run: |
        python scripts/validation/validate_models.py
    
    - name: Run model tests
      run: |
        pytest tests/test_models.py -v
EOF

    log "GitHub Actions workflows created."
}

# Create issue and PR templates
create_github_templates() {
    log "Creating GitHub issue and PR templates..."
    
    # Bug report template
    cat > .github/ISSUE_TEMPLATE/bug_report.md << 'EOF'
---
name: Bug report
about: Create a report to help us improve
title: '[BUG] '
labels: bug
assignees: ''
---

**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Environment (please complete the following information):**
 - OS: [e.g. Ubuntu 20.04]
 - Python version: [e.g. 3.9.7]
 - PyTorch version: [e.g. 2.0.1]
 - CUDA version: [e.g. 11.8]
 - GPU: [e.g. NVIDIA RTX 3080]

**Additional context**
Add any other context about the problem here.

**Medical Data Handling**
- [ ] This issue involves medical data
- [ ] PHI protection measures are in place
- [ ] Ethical approval obtained (if applicable)
EOF

    # Feature request template
    cat > .github/ISSUE_TEMPLATE/feature_request.md << 'EOF'
---
name: Feature request
about: Suggest an idea for this project
title: '[FEATURE] '
labels: enhancement
assignees: ''
---

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Medical/Educational Context**
- [ ] This feature is for medical education
- [ ] This feature involves patient data
- [ ] This feature requires clinical validation

**Implementation Details**
- Estimated complexity: [Low/Medium/High]
- Required expertise: [ML/AR/Medical/Software Engineering]
- Dependencies: [List any new dependencies]

**Additional context**
Add any other context or screenshots about the feature request here.
EOF

    # Pull request template
    cat > .github/PULL_REQUEST_TEMPLATE.md << 'EOF'
## Description
Brief description of the changes in this PR.

## Type of Change
- [ ] Bug fix (non-breaking change which fixes an issue)
- [ ] New feature (non-breaking change which adds functionality)
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Documentation update
- [ ] Performance improvement
- [ ] Code refactoring

## Testing
- [ ] Unit tests pass
- [ ] Integration tests pass
- [ ] Manual testing completed
- [ ] Model validation completed (if applicable)

## Medical Data and Ethics
- [ ] No medical data involved
- [ ] Medical data properly anonymized
- [ ] PHI protection measures verified
- [ ] Ethical guidelines followed

## Documentation
- [ ] Code is self-documenting
- [ ] Docstrings updated
- [ ] README updated (if needed)
- [ ] API documentation updated (if needed)

## Checklist
- [ ] My code follows the style guidelines of this project
- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes

## Screenshots (if applicable)
Add screenshots to help explain your changes.

## Additional Notes
Any additional information that reviewers should know.
EOF

    log "GitHub templates created."
}

# Create Docker configuration
create_docker_config() {
    log "Creating Docker configuration..."
    
    # Main Dockerfile
    cat > Dockerfile << 'EOF'
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    git \
    wget \
    curl \
    vim \
    htop \
    tmux \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Set up Python environment
RUN python3 -m pip install --upgrade pip setuptools wheel

# Create working directory
WORKDIR /app

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copy source code
COPY src/ ./src/
COPY configs/ ./configs/
COPY scripts/ ./scripts/

# Create necessary directories
RUN mkdir -p /app/models /app/data /app/logs /app/outputs

# Set permissions
RUN chmod +x scripts/*.py

# Expose ports
EXPOSE 8000 8080

# Default command
CMD ["python3", "src/arlmt_core/main.py"]
EOF

    # Docker Compose for development
    cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  arlmt-dev:
    build: .
    container_name: arlmt-development
    volumes:
      - .:/app
      - ./models:/app/models
      - ./data:/app/data
      - ./logs:/app/logs
    ports:
      - "8000:8000"
      - "8080:8080"
      - "6006:6006"  # TensorBoard
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app/src
    runtime: nvidia
    stdin_open: true
    tty: true
    command: /bin/bash

  arlmt-training:
    build: .
    container_name: arlmt-training
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./logs:/app/logs
      - ./configs:/app/configs
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app/src
    runtime: nvidia
    command: python3 scripts/training/train_qlora.py --config configs/training/qlora_config.yaml

  arlmt-inference:
    build: .
    container_name: arlmt-inference
    volumes:
      - ./models:/app/models
      - ./data:/app/data
    ports:
      - "8000:8000"
    environment:
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app/src
    runtime: nvidia
    command: python3 src/arlmt_core/inference_server.py

  tensorboard:
    build: .
    container_name: arlmt-tensorboard
    volumes:
      - ./logs:/app/logs
    ports:
      - "6006:6006"
    command: tensorboard --logdir=/app/logs --host=0.0.0.0 --port=6006
EOF

    # Development Docker Compose
    cat > docker-compose.dev.yml << 'EOF'
version: '3.8'

services:
  arlmt-dev:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: arlmt-dev
    volumes:
      - .:/app
      - /tmp/.X11-unix:/tmp/.X11-unix:rw
    ports:
      - "8000:8000"
      - "8080:8080"
      - "8888:8888"  # Jupyter
      - "6006:6006"  # TensorBoard
    environment:
      - DISPLAY=${DISPLAY}
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app/src
    runtime: nvidia
    stdin_open: true
    tty: true
    command: /bin/bash
EOF

    log "Docker configuration created."
}

# Create development scripts
create_dev_scripts() {
    log "Creating development scripts..."
    
    # Setup script
    cat > scripts/setup.sh << 'EOF'
#!/bin/bash
# Development environment setup script

set -e

echo "Setting up ARLMT development environment..."

# Create virtual environment
if [[ ! -d "venv" ]]; then
    python3 -m venv venv
    echo "Virtual environment created."
fi

# Activate virtual environment
source venv/bin/activate

# Upgrade pip
pip install --upgrade pip

# Install dependencies
echo "Installing dependencies..."
pip install -r requirements.txt

# Install development dependencies
echo "Installing development dependencies..."
pip install pytest pytest-cov black isort flake8 mypy pre-commit jupyter

# Install pre-commit hooks
echo "Setting up pre-commit hooks..."
pre-commit install

# Create necessary directories
mkdir -p {models,data,logs,outputs,checkpoints}

echo "Development environment setup completed!"
echo "Activate the environment with: source venv/bin/activate"
EOF

    # Training script
    cat > scripts/training/train_qlora.py << 'EOF'
#!/usr/bin/env python3
"""
QLoRA Training Script for ARLMT System

This script handles the fine-tuning of LLaVA-Med using QLoRA
for the ARLMT medical teaching system.
"""

import argparse
import logging
import os
import sys
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent.parent.parent / "src"))

from arlmt_core.config import load_config
from qlora_implementation.trainer import QLoRATrainer
from utils.logging_utils import setup_logging


def main():
    parser = argparse.ArgumentParser(description="Train ARLMT with QLoRA")
    parser.add_argument(
        "--config", 
        type=str, 
        required=True,
        help="Path to training configuration file"
    )
    parser.add_argument(
        "--resume", 
        type=str, 
        default=None,
        help="Path to checkpoint to resume from"
    )
    parser.add_argument(
        "--output-dir", 
        type=str, 
        default="./outputs",
        help="Output directory for models and logs"
    )
    
    args = parser.parse_args()
    
    # Setup logging
    setup_logging(args.output_dir)
    logger = logging.getLogger(__name__)
    
    logger.info("Starting ARLMT QLoRA training...")
    
    # Load configuration
    config = load_config(args.config)
    
    # Initialize trainer
    trainer = QLoRATrainer(config, args.output_dir)
    
    # Resume from checkpoint if specified
    if args.resume:
        trainer.load_checkpoint(args.resume)
        logger.info(f"Resumed training from {args.resume}")
    
    # Start training
    trainer.train()
    
    logger.info("Training completed successfully!")


if __name__ == "__main__":
    main()
EOF

    # Evaluation script
    cat > scripts/evaluation/evaluate_model.py << 'EOF'
#!/usr/bin/env python3
"""
Model Evaluation Script for ARLMT System

This script evaluates the performance of trained ARLMT models
on various medical education benchmarks.
"""

import argparse
import json
import logging
import sys
from pathlib import Path

# Add src to path
sys.path.append(str(Path(__file__).parent.parent.parent / "src"))

from evaluation.medical_qa_evaluator import MedicalQAEvaluator
from evaluation.ar_performance_evaluator import ARPerformanceEvaluator
from utils.logging_utils import setup_logging


def main():
    parser = argparse.ArgumentParser(description="Evaluate ARLMT model")
    parser.add_argument(
        "--model-path", 
        type=str, 
        required=True,
        help="Path to trained model"
    )
    parser.add_argument(
        "--eval-data", 
        type=str, 
        required=True,
        help="Path to evaluation dataset"
    )
    parser.add_argument(
        "--output-dir", 
        type=str, 
        default="./evaluation_results",
        help="Output directory for evaluation results"
    )
    parser.add_argument(
        "--eval-type", 
        type=str, 
        choices=["medical_qa", "ar_performance", "all"],
        default="all",
        help="Type of evaluation to perform"
    )
    
    args = parser.parse_args()
    
    # Setup logging
    setup_logging(args.output_dir)
    logger = logging.getLogger(__name__)
    
    logger.info("Starting ARLMT model evaluation...")
    
    results = {}
    
    # Medical QA evaluation
    if args.eval_type in ["medical_qa", "all"]:
        logger.info("Running Medical QA evaluation...")
        qa_evaluator = MedicalQAEvaluator(args.model_path)
        qa_results = qa_evaluator.evaluate(args.eval_data)
        results["medical_qa"] = qa_results
        logger.info(f"Medical QA Accuracy: {qa_results['accuracy']:.3f}")
    
    # AR Performance evaluation
    if args.eval_type in ["ar_performance", "all"]:
        logger.info("Running AR Performance evaluation...")
        ar_evaluator = ARPerformanceEvaluator(args.model_path)
        ar_results = ar_evaluator.evaluate(args.eval_data)
        results["ar_performance"] = ar_results
        logger.info(f"AR Response Time: {ar_results['avg_response_time']:.3f}ms")
    
    # Save results
    results_file = Path(args.output_dir) / "evaluation_results.json"
    with open(results_file, "w") as f:
        json.dump(results, f, indent=2)
    
    logger.info(f"Evaluation completed! Results saved to {results_file}")


if __name__ == "__main__":
    main()
EOF

    # Make scripts executable
    chmod +x scripts/setup.sh
    chmod +x scripts/training/train_qlora.py
    chmod +x scripts/evaluation/evaluate_model.py
    
    log "Development scripts created."
}

# Create configuration files
create_config_files() {
    log "Creating configuration files..."
    
    # Training configuration
    cat > configs/training/qlora_config.yaml << 'EOF'
# QLoRA Training Configuration for ARLMT

model:
  base_model: "liuhaotian/llava-v1.5-7b"
  model_type: "llava"
  torch_dtype: "float16"
  device_map: "auto"

qlora:
  r: 64
  lora_alpha: 16
  target_modules:
    - "q_proj"
    - "v_proj"
    - "k_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  lora_dropout: 0.05
  bias: "none"
  task_type: "CAUSAL_LM"
  use_rslora: true
  use_dora: false

training:
  output_dir: "./outputs/qlora_training"
  num_train_epochs: 3
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 8
  learning_rate: 2e-4
  weight_decay: 0.01
  warmup_ratio: 0.03
  lr_scheduler_type: "cosine"
  logging_steps: 10
  save_steps: 500
  eval_steps: 500
  save_total_limit: 3
  evaluation_strategy: "steps"
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false
  report_to: "tensorboard"
  dataloader_num_workers: 4
  remove_unused_columns: false
  fp16: true
  gradient_checkpointing: true
  deepspeed: null

data:
  train_data_path: "./data/medical_qa_train.json"
  eval_data_path: "./data/medical_qa_eval.json"
  max_length: 2048
  image_size: 336
  image_aspect_ratio: "pad"

logging:
  log_level: "INFO"
  log_file: "./logs/training.log"
  tensorboard_dir: "./logs/tensorboard"

checkpointing:
  save_strategy: "steps"
  save_steps: 500
  save_total_limit: 3
  resume_from_checkpoint: null
EOF

    # Inference configuration
    cat > configs/deployment/inference_config.yaml << 'EOF'
# Inference Configuration for ARLMT

model:
  model_path: "./models/arlmt_qlora"
  device: "cuda"
  torch_dtype: "float16"
  load_in_8bit: false
  load_in_4bit: true

generation:
  max_new_tokens: 512
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  do_sample: true
  num_beams: 1
  repetition_penalty: 1.1
  length_penalty: 1.0

ar_interface:
  device_type: "inmo_air2"
  resolution: [1920, 1080]
  refresh_rate: 60
  field_of_view: 50
  tracking_enabled: true
  gesture_recognition: true

performance:
  max_batch_size: 4
  max_concurrent_requests: 10
  timeout_seconds: 30
  cache_size: 100
  enable_streaming: true

api:
  host: "0.0.0.0"
  port: 8000
  cors_origins: ["*"]
  rate_limit: "100/minute"
  auth_required: false

logging:
  log_level: "INFO"
  log_file: "./logs/inference.log"
  access_log: "./logs/access.log"
  metrics_enabled: true
EOF

    log "Configuration files created."
}

# Add files to git
add_files_to_git() {
    log "Adding files to Git repository..."
    
    # Add all created files
    git add .
    
    # Create initial commit
    git commit -m "Initial commit: ARLMT Medical AR Teaching System

- Added comprehensive project structure
- Implemented QLoRA fine-tuning pipeline
- Created AR interface integration
- Added evaluation and benchmarking tools
- Configured CI/CD workflows
- Added Docker containerization
- Created documentation templates
- Implemented PLOS journal compliance
- Added GigaDB submission preparation

Features:
- LLaVA-Med integration with QLoRA optimization
- INMO Air2 AR glasses support
- Medical education scenario generation
- Real-time performance monitoring
- Comprehensive testing framework
- Automated deployment pipeline"
    
    log "Initial commit created."
}

# Create GitHub repository (if gh CLI is available)
create_github_repo() {
    log "Creating GitHub repository..."
    
    if ! command -v gh &> /dev/null; then
        warn "GitHub CLI not available. Please create repository manually at:"
        warn "https://github.com/new"
        warn "Repository name: $REPO_NAME"
        warn "Description: $REPO_DESCRIPTION"
        return
    fi
    
    # Check if already logged in
    if ! gh auth status &> /dev/null; then
        warn "Please login to GitHub CLI first: gh auth login"
        return
    fi
    
    # Create repository
    gh repo create "$REPO_NAME" \
        --description "$REPO_DESCRIPTION" \
        --public \
        --clone=false \
        --add-readme=false
    
    # Add remote
    git remote add origin "https://github.com/$GITHUB_USERNAME/$REPO_NAME.git"
    
    # Push to GitHub
    git branch -M main
    git push -u origin main
    
    log "Repository created and pushed to GitHub!"
    info "Repository URL: https://github.com/$GITHUB_USERNAME/$REPO_NAME"
}

# Setup repository settings
setup_repo_settings() {
    log "Setting up repository settings..."
    
    if ! command -v gh &> /dev/null; then
        warn "GitHub CLI not available. Please configure repository settings manually."
        return
    fi
    
    # Enable features
    gh repo edit --enable-issues --enable-projects --enable-wiki
    
    # Set up branch protection
    gh api repos/$GITHUB_USERNAME/$REPO_NAME/branches/main/protection \
        --method PUT \
        --field required_status_checks='{"strict":true,"contexts":["test"]}' \
        --field enforce_admins=true \
        --field required_pull_request_reviews='{"required_approving_review_count":1}' \
        --field restrictions=null
    
    # Add topics
    gh repo edit --add-topic "medical-education" \
                 --add-topic "augmented-reality" \
                 --add-topic "machine-learning" \
                 --add-topic "qlora" \
                 --add-topic "llava" \
                 --add-topic "pytorch" \
                 --add-topic "medical-ai" \
                 --add-topic "ar-glasses"
    
    log "Repository settings configured."
}

# Generate project summary
generate_summary() {
    log "Generating project summary..."
    
    cat << EOF

${GREEN}========================================${NC}
${GREEN}  ARLMT GitHub Repository Setup Complete${NC}
${GREEN}========================================${NC}

${BLUE}Repository Information:${NC}
  Name: $REPO_NAME
  Description: $REPO_DESCRIPTION
  URL: https://github.com/$GITHUB_USERNAME/$REPO_NAME
  Project Board: $PROJECT_URL

${BLUE}Key Features Implemented:${NC}
  âœ“ Comprehensive project structure
  âœ“ QLoRA fine-tuning pipeline
  âœ“ AR interface integration
  âœ“ CI/CD workflows
  âœ“ Docker containerization
  âœ“ Testing framework
  âœ“ Documentation templates
  âœ“ PLOS journal compliance
  âœ“ GigaDB submission plan

${BLUE}Next Steps:${NC}
  1. Review and customize configuration files
  2. Add your model weights to models/ directory
  3. Prepare training data in data/ directory
  4. Run initial tests: pytest tests/
  5. Start development: source venv/bin/activate
  6. Begin training: python scripts/training/train_qlora.py

${BLUE}Important Files Created:${NC}
  ðŸ“„ README.md - Main project documentation
  ðŸ“„ CONTRIBUTING.md - Contribution guidelines
  ðŸ“„ DATA_AVAILABILITY.md - Data sharing information
  ðŸ“„ GIGADB_SUBMISSION_PLAN.md - GigaDB submission guide
  ðŸ“„ requirements.txt - Python dependencies
  ðŸ“„ Dockerfile - Container configuration
  ðŸ“„ .github/workflows/ - CI/CD pipelines

${YELLOW}Remember to:${NC}
  - Update configuration files with your specific settings
  - Add your actual model weights and data
  - Customize documentation for your use case
  - Set up proper secrets for CI/CD
  - Configure GigaDB submission when ready

EOF
}

# Main execution
main() {
    log "Starting ARLMT GitHub repository setup..."
    
    check_prerequisites
    init_git_repo
    create_gitignore
    setup_git_lfs
    organize_repository
    create_github_workflows
    create_github_templates
    create_docker_config
    create_dev_scripts
    create_config_files
    add_files_to_git
    create_github_repo
    setup_repo_settings
    generate_summary
    
    log "ARLMT GitHub repository setup completed successfully!"
}

# Run main function
main "$@"